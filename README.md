# ğŸ‡¨ğŸ‡± Scrap Jobs Chile

Sistema modular de web scraping para ofertas de trabajo tecnolÃ³gicas en Chile. Automatiza la recolecciÃ³n de oportunidades laborales desde mÃºltiples empresas chilenas del sector tech con **salida simple en archivos JSON**.

## ğŸš€ CaracterÃ­sticas

- **Sistema Modular**: Scrapers independientes para cada empresa
- **Pipeline Unificado**: ConsolidaciÃ³n automÃ¡tica de resultados
- **Filtrado Inteligente**: Sistema avanzado de tags y filtros
- **EjecuciÃ³n Paralela**: Soporte para scraping concurrente
- **DetecciÃ³n de Duplicados**: EliminaciÃ³n automÃ¡tica de ofertas repetidas
- **EstadÃ­sticas Detalladas**: AnÃ¡lisis completo de los datos recolectados
- **Sin Base de Datos**: Todo se guarda en archivos JSON simples
- **Zero Config**: Funciona inmediatamente sin configuraciones complejas

## ğŸ¢ Empresas Soportadas

- **ğŸ›’ Falabella** - API con autenticaciÃ³n
- **ğŸ’° Fintual** - IntegraciÃ³n con Lever
- **ğŸ“¡ Entel** - Portal corporativo
- **ğŸ¦‹ Betterfly** - Portal moderno de carreras
- **ğŸ”§ SONDA** - Portal tech especializado
- **ğŸ¨ APIUX Tech** - IntegraciÃ³n TeamTailor
- **ğŸ¦ Banco Estado** - API simple
- **ğŸš€ DesafÃ­o Latam** - Portal educativo con Lever
- **ğŸŒŸ Accenture** - Portal de carreras multinacional

## ğŸ“‹ Requisitos

- **Bun** >= 1.0.0 (recomendado) o Node.js >= 14.0.0

## ğŸ› ï¸ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/valentin-marquez/scrap-jobs-chile.git
cd scrap-jobs-chile

# Instalar dependencias con Bun (recomendado)
bun install

# O con npm si prefieres
npm install

# Crear directorio de salida
bun run setup
```

## ğŸš€ Uso

### Ejecutar todos los scrapers

```bash
# Ejecutar pipeline completo (modo secuencial recomendado)
bun start

# Modo paralelo (mÃ¡s rÃ¡pido, pero cuidado con rate limits)
bun run scrape:parallel
```

### Ejecutar scrapers individuales

```bash
# Scraper especÃ­fico
bun run scrape:accenture
bun run scrape:falabella
bun run scrape:bancochile
bun run scrape:desafiolatam
```

### Scripts Ãºtiles

```bash
# Limpiar archivos de salida
bun run clean

# Probar sistema de tags
bun run test:tags

# DemostraciÃ³n del sistema de tags
bun run demo:tags
```

## ğŸ“Š Resultados

Los datos se guardan automÃ¡ticamente en el directorio `output/`:

```
output/
â”œâ”€â”€ all_jobs.json           # ğŸ“„ Todas las ofertas consolidadas
â”œâ”€â”€ pipeline_stats.json     # ğŸ“Š EstadÃ­sticas detalladas del scraping
â”œâ”€â”€ accenture_jobs.json     # ğŸŒŸ Solo trabajos de Accenture
â”œâ”€â”€ falabella_jobs.json     # ğŸ›’ Solo trabajos de Falabella
â””â”€â”€ ...                     # Otros archivos por empresa
```

### Formato de datos

```json
{
  "id": "unique-job-id",
  "title": "Desarrollador Full Stack",
  "company": "Accenture",
  "location": "Santiago, Chile",
  "description": "# Desarrollador Full Stack\n\n## DescripciÃ³n del Puesto...",
  "jobUrl": "https://accenture.com/careers/job/123",
  "tags": ["javascript", "react", "nodejs", "consulting", "technology"],
  "department": "Technology",
  "jobType": "Full-time",
  "publishedDate": "2025-06-02T10:00:00Z",
  "metadata": {
    "source": "Accenture Careers API",
    "scraper": "AccentureScraper",
    "scrapedAt": "2025-06-02T15:30:00Z"
  }
}
```

## âš™ï¸ ConfiguraciÃ³n Simple

### Filtros Globales

Puedes modificar los filtros directamente en `src/main.js`:

```javascript
const globalFilters = {
  requiredTags: [], // Solo trabajos con estos tags: ['javascript', 'python']
  excludeTags: [],  // Excluir trabajos: ['senior', 'lead']
  locations: ['chile'], // Solo ubicaciones: ['chile', 'santiago']
  maxAge: 7 // Solo trabajos de los Ãºltimos 7 dÃ­as
};
```

### Habilitar/Deshabilitar Scrapers

```javascript
// En src/main.js, cambia enabled: true/false
pipeline.registerScraper('accenture', accentureScraper, {
  enabled: true,  // â† Cambiar a false para deshabilitar
  priority: 10,
  filters: {
    locations: ['chile', 'santiago'],
    excludeTags: [],
  },
});
```

## ğŸ·ï¸ Sistema de Tags Inteligente

El sistema extrae automÃ¡ticamente tecnologÃ­as del texto de las ofertas:

- **Lenguajes**: JavaScript, Python, Java, C#, Go, Rust, etc.
- **Frameworks**: React, Angular, Vue, Django, Express, etc.
- **Bases de datos**: PostgreSQL, MongoDB, MySQL, Redis, etc.
- **Cloud**: AWS, Azure, GCP, Docker, Kubernetes, etc.
- **MetodologÃ­as**: Agile, Scrum, DevOps, etc.

### Filtrado inteligente

- âœ… Evita falsos positivos (ej: "rust" en "rÃºsticos")
- âœ… Normaliza variaciones (ej: "JS" â†’ "javascript")
- âœ… CategorizaciÃ³n automÃ¡tica por tipo de tecnologÃ­a
- âœ… EspecÃ­fico para el mercado tech chileno

## ğŸ“ˆ EstadÃ­sticas AutomÃ¡ticas

El pipeline genera estadÃ­sticas detalladas en `pipeline_stats.json`:

```json
{
  "totalJobs": 28,
  "uniqueCompanies": 6,
  "uniqueTags": 72,
  "topTags": {
    "sql": 7,
    "technology": 6,
    "consulting": 6,
    "java": 6
  },
  "byCompany": {
    "SONDA": 7,
    "Falabella": 7,
    "Accenture": 6
  }
}
```

## ğŸ”§ Desarrollo y Calidad de CÃ³digo

Este proyecto utiliza **Biome.js** como linter y formateador:

```bash
# Verificar problemas de linting
bun run lint

# Corregir problemas automÃ¡ticamente
bun run lint:fix

# Formatear cÃ³digo
bun run format:write

# Verificar y aplicar todas las correcciones
bun run check:fix
```

## ğŸ—ï¸ Estructura del Proyecto

```
src/
â”œâ”€â”€ main.js                 # ğŸš€ Punto de entrada principal
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.js          # âš™ï¸ Configuraciones (opcional)
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base-scraper.js    # ğŸ—ï¸ Clase base para scrapers
â”‚   â”œâ”€â”€ scraping-pipeline.js # ğŸ”„ Pipeline unificado
â”‚   â”œâ”€â”€ accenture.scrap.js # ğŸŒŸ Scraper de Accenture
â”‚   â”œâ”€â”€ falabella.scrap.js # ğŸ›’ Scraper de Falabella
â”‚   â””â”€â”€ ...                # Otros scrapers
â””â”€â”€ utils/
    â”œâ”€â”€ common_tags.js     # ğŸ·ï¸ Sistema de tags
    â””â”€â”€ tag-system-demo.js # ğŸ§ª DemostraciÃ³n de tags
```

## âœ¨ Ventajas del Sistema

- **ğŸš€ RÃ¡pido**: Powered by Bun para mÃ¡ximo rendimiento
- **ğŸ“¦ Simple**: Sin bases de datos, sin configuraciones complejas
- **ğŸ”§ Modular**: FÃ¡cil agregar nuevos scrapers
- **ğŸ“Š Completo**: EstadÃ­sticas detalladas automÃ¡ticas
- **ğŸ·ï¸ Inteligente**: Sistema avanzado de extracciÃ³n de tags
- **ğŸ‡¨ğŸ‡± Local**: Optimizado para el mercado tech chileno

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-empresa`)
3. Commit tus cambios (`git commit -am 'Agregar scraper para NuevaEmpresa'`)
4. Push a la rama (`git push origin feature/nueva-empresa`)
5. Abre un Pull Request

## ğŸ“ Notas importantes

- **Rate Limiting**: Algunos sitios tienen lÃ­mites de velocidad. Usar modo secuencial si hay errores.
- **TÃ©rminos de Uso**: AsegÃºrate de cumplir con los tÃ©rminos de servicio de cada sitio.
- **Ã‰tica**: Usa este proyecto de manera responsable y Ã©tica.

## ğŸ› Problemas conocidos

- Algunos scrapers pueden fallar si las empresas cambian su estructura web
- El modo paralelo puede causar rate limiting en sitios sensibles

## ğŸ“ Soporte

Si encuentras problemas o tienes sugerencias:

1. Revisa los [Issues existentes](https://github.com/valentin-marquez/scrap-jobs-chile/issues)
2. Abre un nuevo Issue con detalles del problema
3. Incluye logs y configuraciÃ³n relevante

---

â­ **Â¡Si este proyecto te resulta Ãºtil, dale una estrella!** â­

**âœ¨ Sistema simple, potente y listo para usar âœ¨**